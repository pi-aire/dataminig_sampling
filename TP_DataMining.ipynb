{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT5_WhBiUnw6"
   },
   "source": [
    "# Échantillonnage direct de l'espace des motifs\n",
    "\n",
    "### BRUNEAU Richard - VASLIN Pierre\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hfUuyvYBX6aH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sps\n",
    "import math\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class DataSet():\n",
    "    def __init__(self,df:pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.sizes = np.zeros(self.df.shape[0],dtype=int)\n",
    "        for i in range(self.df.shape[0]):\n",
    "            self.sizes[i] = self.df.iloc[i].count()\n",
    "        # Sizes est pour connaitre la taille d'une ligne en o(1)\n",
    "        # Pandas gère mal la variation du nombre de colonne dans une ligne dans un dataFrame, par concéquent \n",
    "        # il recalcule à chaque fois le nombre d'éléments non null o(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "gOavPKYmYF_A",
    "outputId": "2261f7eb-c140-40e7-a387-f68a1d6d7ef9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  27  28  29  30  31  32  33  \\\n",
       "0   1   3   5   7   9  11  13  15  17  19  ...  56  58  60  62  64  66  68   \n",
       "1   1   3   5   7   9  12  13  15  17  19  ...  56  58  60  62  64  66  68   \n",
       "2   1   3   5   7   9  12  13  16  17  19  ...  56  58  60  62  64  66  68   \n",
       "3   1   3   5   7   9  11  13  15  17  20  ...  56  58  60  62  64  66  68   \n",
       "4   1   3   5   7   9  11  13  15  17  19  ...  56  58  60  62  64  66  68   \n",
       "\n",
       "   34  35  36  \n",
       "0  70  72  74  \n",
       "1  70  72  74  \n",
       "2  70  72  74  \n",
       "3  70  72  74  \n",
       "4  70  72  74  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Le dataframe pour les tests\n",
    "df = pd.read_table(\"https://bitbucket.org/anesbendimerad/sigibbssamplingcode/raw/6699a50508fe177ee0c00dcc7d8e5390ee53688a/ItemsetDatasets/chess.txt\", sep=\" \",header=None)\n",
    "del df[37]\n",
    "ds = DataSet(df)\n",
    "ds.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BKmRcvRXodb"
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YjH1fyI4VEAd"
   },
   "outputs": [],
   "source": [
    "def algoFrequences(ds:DataSet,nb_pattern)-> tuple:\n",
    "  df = ds.df\n",
    "  sizes = ds.sizes\n",
    "  R = []\n",
    "  IsInR = set()\n",
    "  P: dict = dict()\n",
    "  w = np.zeros(df.shape[0])\n",
    "  totalW = 0\n",
    "    \n",
    "  # set les probas\n",
    "  for i in range(len(w)):\n",
    "    w[i] = math.pow(2,sizes[i])\n",
    "    totalW += w[i]\n",
    "  \n",
    "  # on selectionne \n",
    "  while len(R) < nb_pattern:\n",
    "    random_row = random.uniform(0,totalW)\n",
    "    # On cherche la ligne\n",
    "    row = 0\n",
    "    v = 0\n",
    "    for i in range(len(w)):\n",
    "      if  v > random_row:\n",
    "        row = i - 1\n",
    "        break\n",
    "      v += w[i]\n",
    "    # On selectionne un motif \n",
    "    pattern = np.array(df.iloc[row][:sizes[row]])\n",
    "    random_v = random.randint(1, len(pattern) - 1 )\n",
    "    for i in range(len(pattern)- random_v):\n",
    "      pattern = np.delete(pattern, random.randint(0, len(pattern) - 1 ))\n",
    "    # On ajoute seulement les motifs non présent dans l'ensemble R\n",
    "    IsInR.add(np.array2string(pattern))\n",
    "    if len(IsInR) != len(R):\n",
    "      R.append(pattern)\n",
    "  return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_dlL3MrwwbC",
    "outputId": "0dde1ad1-8915-444f-ff22-2a79cba3d745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([11, 15, 17, 19, 27, 34, 36, 40, 46, 66, 69, 70], dtype=int64),\n",
       " array([ 1,  3,  6,  7, 14, 24, 25, 27, 40, 43, 46, 50, 52, 56, 58, 60, 62,\n",
       "        65, 66, 73, 74], dtype=int64),\n",
       " array([ 3,  9, 12, 21, 27, 31, 40, 56, 64], dtype=int64),\n",
       " array([19, 27, 48], dtype=int64),\n",
       " array([ 2,  3,  7,  9, 12, 14, 16, 17, 20, 21, 23, 25, 27, 29, 31, 34, 36,\n",
       "        38, 40, 42, 44, 47, 48, 51, 52, 55, 56, 58, 60, 62, 64, 66, 69, 70,\n",
       "        72, 75], dtype=int64),\n",
       " array([ 3,  5,  9, 11, 13, 15, 17, 19, 21, 24, 25, 27, 29, 31, 40, 43, 46,\n",
       "        48, 51, 52, 54, 57, 58, 60, 62, 65, 66, 69, 70, 73, 74],\n",
       "       dtype=int64),\n",
       " array([ 2,  5,  8,  9, 11, 14, 16, 17, 21, 25, 33, 34, 40, 51, 52, 54, 57,\n",
       "        60, 62, 69, 71, 72], dtype=int64),\n",
       " array([ 3,  7, 15, 62, 70], dtype=int64),\n",
       " array([ 2,  5,  7,  9, 16, 20, 21, 23, 25, 34, 36, 38, 40, 42, 44, 47, 48,\n",
       "        52, 55, 56, 58, 62, 64, 69, 75], dtype=int64),\n",
       " array([ 1,  3,  5, 14, 21, 34, 38, 40, 48, 64], dtype=int64)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoFrequences(ds,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PM8vykS4XZmw"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NJGeGtYlXfLJ"
   },
   "outputs": [],
   "source": [
    "def algoArea(ds:DataSet,nb_pattern)-> tuple:\n",
    "  df = ds.df\n",
    "  sizes = ds.sizes\n",
    "  R = []\n",
    "  IsInR = set()\n",
    "  \n",
    "  # set les probas\n",
    "  w = np.zeros(df[0].count(),dtype=np.ulonglong)\n",
    "  totalW:np.ulonglong= 0\n",
    "  for i in range(1, len(w)):\n",
    "    w[i] = np.multiply(sizes[i], np.power(2, (sizes[i] - 1)))\n",
    "    totalW += w[i]\n",
    "  \n",
    "  # on selectionne \n",
    "  while len(R) < nb_pattern:\n",
    "    # On cherche la ligne\n",
    "    random_row = random.uniform(0,totalW)\n",
    "    v, row = 0,0\n",
    "    for i in range(len(w)):\n",
    "      if v > random_row:\n",
    "        row = i - 1\n",
    "        break\n",
    "      v += w[i]\n",
    "      \n",
    "    # On set les probabilités de k (taille du motif)\n",
    "    # On souhaite que le sous-ensemble est une taille calculée \n",
    "    # proportionnellement avec les tailles des datarecords (lignes) \n",
    "    ks = np.zeros(int(sizes[row]))\n",
    "    totalK = 0\n",
    "    for i in range(len(ks)):\n",
    "        ks[i] = sps.binom(len(ks), i + 1)\n",
    "        totalK += ks[i]\n",
    "    #totalK = (len(ks) * (len(ks)+1))/2\n",
    "    random_kp = random.uniform(0, totalK)\n",
    "    # On cherche la ligne\n",
    "    k, v = 0,0\n",
    "    for i in range(len(ks)):\n",
    "      if v > random_kp:\n",
    "        k = i - 1\n",
    "        break\n",
    "      v += ks[i]\n",
    "    \n",
    "    pattern = np.array(df.iloc[row][:sizes[row]])\n",
    "    for i in range(len(pattern)- k):\n",
    "      pattern = np.delete(pattern, random.randint(0, len(pattern) - 1 ))\n",
    "    \n",
    "    # On ajoute seulement les motifs non présents dans l'ensemble R\n",
    "    IsInR.add(np.array2string(pattern))\n",
    "    if len(IsInR) != len(R):\n",
    "      R.append(pattern)\n",
    "  return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBN3lSJzlpqx",
    "outputId": "25f47460-6203-4869-b317-e9627f042c14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 5,  9, 13, 17, 19, 21, 23, 42, 44, 50, 54, 60, 64, 70],\n",
       "       dtype=int64),\n",
       " array([ 5,  9, 11, 15, 17, 27, 31, 34, 40, 42, 44, 50, 52, 54, 62, 64],\n",
       "       dtype=int64),\n",
       " array([ 1,  3,  7,  9, 19, 23, 29, 31, 40, 42, 44, 46, 52, 56, 58],\n",
       "       dtype=int64),\n",
       " array([ 1,  3,  7,  9, 13, 25, 29, 31, 34, 36, 38, 42, 48, 54, 58, 60, 62,\n",
       "        64, 68, 72, 74], dtype=int64),\n",
       " array([ 1,  7,  9, 17, 19, 21, 23, 25, 31, 34, 36, 38, 42, 52, 56, 60, 62,\n",
       "        64, 68, 72], dtype=int64),\n",
       " array([ 5,  9, 15, 17, 21, 23, 27, 40, 42, 46, 50, 54, 60, 62, 66, 68, 70,\n",
       "        74], dtype=int64),\n",
       " array([ 1,  5,  7,  9, 11, 23, 29, 48, 52, 58, 62, 70, 74], dtype=int64),\n",
       " array([ 9, 15, 27, 29, 31, 34, 44, 46, 50, 52, 62, 66, 68, 70, 72, 74],\n",
       "       dtype=int64),\n",
       " array([ 3,  5,  7, 15, 23, 27, 29, 31, 34, 36, 40, 42, 48, 52, 54, 56, 58,\n",
       "        60, 62, 64, 70], dtype=int64),\n",
       " array([ 1,  5,  7, 15, 17, 19, 25, 27, 31, 40, 42, 44, 56, 60, 68, 72],\n",
       "       dtype=int64)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algoArea(ds,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCp4sUmdXi7L"
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RtVA7H1OXhXs"
   },
   "outputs": [],
   "source": [
    "def frequences(ds, patterns):\n",
    "  df = ds.df\n",
    "  sizes = ds.sizes\n",
    "  frequencesP = np.zeros(len(patterns),dtype=float)\n",
    "  indexs = np.zeros(len(patterns),dtype=int)\n",
    "  lenPat = len(patterns)\n",
    "  for i in range(df.shape[0]):\n",
    "    indexs[True] = 0\n",
    "    for j in range(ds.sizes[i]):\n",
    "      for ip in range(lenPat):\n",
    "        if (len(patterns[ip])!= indexs[ip] and \n",
    "            df.iloc[i][j] == patterns[ip][indexs[ip]]):\n",
    "          indexs[ip] += 1\n",
    "          if len(patterns[ip]) == indexs[ip]:\n",
    "            frequencesP[ip] += 1.\n",
    "  for i in range(len(frequencesP)):\n",
    "    frequencesP[i] = (frequencesP[i])/float(df.shape[0])\n",
    "  return frequencesP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "grB3Wa0XNvwo"
   },
   "outputs": [],
   "source": [
    "patterns = algoFrequences(ds,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyQcmwHAZdu-",
    "outputId": "fca91a17-37d9-44fb-c072-17608eb0caff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00125156, 0.00093867, 0.00031289, 0.00062578, 0.00031289,\n",
       "       0.00125156, 0.00062578, 0.00031289, 0.00031289, 0.02033792])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequences(ds,patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9V9aqi0Jtvcb"
   },
   "outputs": [],
   "source": [
    "def aire(ds, patterns):\n",
    "  df = ds.df\n",
    "  aireP = np.zeros(len(patterns),dtype=int)\n",
    "  indexs = np.zeros(len(patterns),dtype=int)\n",
    "  lenPat = len(patterns)\n",
    "  for i in range(df.shape[0]):\n",
    "    indexs[True] = 0\n",
    "    for j in range(ds.sizes[i]):\n",
    "      for ip in range(lenPat):\n",
    "        if (len(patterns[ip])!= indexs[ip] and \n",
    "            df.iloc[i][j] == patterns[ip][indexs[ip]]):\n",
    "          indexs[ip] += 1\n",
    "          if len(patterns[ip]) == indexs[ip]:\n",
    "            aireP[ip] += 1\n",
    "  for i in range(len(aireP)):\n",
    "    aireP[i] = aireP[i]*len(patterns[i])\n",
    "  return aireP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dY6ppMfqv-Fz"
   },
   "outputs": [],
   "source": [
    "patterns = algoArea(ds,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3T9a2ONWuCJS",
    "outputId": "db2e563c-3fdf-4c15-aaf3-dce4a126f490"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 529,  616,  897, 1424, 1482, 2227,  589, 2784, 2210,  304])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aire(ds,patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_BCCw1aNJ8o"
   },
   "source": [
    "## Question 4 \n",
    "\n",
    "Nous allons maintenant tester nos algorithmes avec des jeux de données suggérés dans le sujet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "lPYElfndNODK",
    "outputId": "09af6bad-133a-4bfe-8903-3cf3ef6c4b35"
   },
   "outputs": [],
   "source": [
    "dataset_1 = pd.read_table(\"https://bitbucket.org/anesbendimerad/sigibbssamplingcode/raw/6699a50508fe177ee0c00dcc7d8e5390ee53688a/ItemsetDatasets/chess.txt\", sep=\" \",header=None)\n",
    "del dataset_1[37]\n",
    "ds1 = DataSet(dataset_1)\n",
    "\n",
    "# On réalise algoFrequence sur le dataset_1 5 fois.\n",
    "dsFrequence1 = algoFrequences(ds1, 5)\n",
    "# On ressort les fréquences \n",
    "freq1 = frequences(ds1, dsFrequence1)\n",
    "\n",
    "# On réalise algoAire sur le dataset_1.\n",
    "dsArea1 = algoArea(ds1, 5)\n",
    "# On ressort les valeurs\n",
    "area1 = aire(ds1, dsArea1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "wS8aFb5CnCcT",
    "outputId": "38e6d175-11d5-41f3-d3fd-b4dab6dac04b"
   },
   "outputs": [],
   "source": [
    "dataset_2 = pd.read_fwf(\"https://www.philippe-fournier-viger.com/spmf/datasets/LEVIATHAN.txt\", sep=\" \",header=None,)\n",
    "dataset_2 = dataset_2[0].str.split(' ', expand=True)\n",
    "ds2 = DataSet(dataset_2)\n",
    "\n",
    "# On réalise algoFrequence sur le dataset_2 5 fois.\n",
    "dsFrequence2 = algoFrequences(ds2, 5)\n",
    "# On ressort les fréquences \n",
    "freq2 = frequences(ds2, dsFrequence2)\n",
    "\n",
    "# On réalise algoAire sur le dataset_2.\n",
    "dsArea2 = algoArea(ds2, 5)\n",
    "# On ressort les valeurs\n",
    "area2 = aire(ds2, dsArea2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "F6zVzfLyn17x",
    "outputId": "4e4c2d68-2406-42ce-fd2d-0b32b4230b9f"
   },
   "outputs": [],
   "source": [
    "dataset_3 = pd.read_fwf(\"https://www.philippe-fournier-viger.com/spmf/datasets/FIFA.txt\", sep=\" \",header=None,)\n",
    "dataset_3 = dataset_3[0].str.split(' ', expand=True)\n",
    "ds3 = DataSet(dataset_3)\n",
    "\n",
    "# On réalise algoFrequence sur le dataset_3 5 fois.\n",
    "dsFrequence3 = algoFrequences(ds3, 5)\n",
    "# On ressort les fréquences \n",
    "freq3 = frequences(ds3, dsFrequence3)\n",
    "\n",
    "# On réalise algoAire sur le dataset_3.\n",
    "dsArea3 = algoArea(ds3, 5)\n",
    "# On ressort les valeurs\n",
    "area3 = aire(ds3, dsArea3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIPlVPxaoFeY",
    "outputId": "7b1973c6-afdb-4f4d-9eb4-42a181d87b84",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_4 = pd.read_fwf(\"https://www.philippe-fournier-viger.com/spmf/datasets/BIBLE.txt\", sep=\" \",header=None,)\n",
    "dataset_4 = dataset_4[0].str.split(' ', expand=True)\n",
    "ds4 = DataSet(dataset_4)\n",
    "\n",
    "# On réalise algoFrequence sur le dataset_4 5 fois.\n",
    "dsFrequence4 = algoFrequences(ds4, 5)\n",
    "# On ressort les fréquences \n",
    "freq4 = frequences(ds4, dsFrequence4)\n",
    "\n",
    "# On réalise algoAire sur le dataset_4.\n",
    "dsArea4 = algoArea(ds4, 5)\n",
    "# On ressort les valeurs\n",
    "area4 = aire(ds4, dsArea4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1uaF6e5pVd2"
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHirqdUqpZEm"
   },
   "source": [
    "### Etude emprique\n",
    "\n",
    "Nous allons maintenant étudier les résultats des datasets testé ci-dessus.\n",
    "\n",
    "#### Dataset n°1\n",
    "\n",
    "##### Algorithme de fréquence\n",
    "\n",
    "Dans un premier temps, nous allons analyser l'algorithme de fréquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccyKbbVRAwl6",
    "outputId": "765b523f-2e46-40e5-889f-80765e659127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons extrait les motifs suivants:\n",
      "[ 3  5  7  9 12 14 15 18 20 22 23 25 28 29 31 34 36 38 40 42 44 46 48 50\n",
      " 52 55 56 58 60 62 64 66 68 70 72 74]\n",
      "[ 3 11 14 15 23 25 29 38 42 46 52 55 60 70 72]\n",
      "[ 1  3  7  9 11 13 15 17 20 23 25 29 31 36 40 42 45 52 55 58 60 63 66 69\n",
      " 72 75]\n",
      "[ 7  9 14 21 25 36 39 48 51 54 56 58 60 62 66 74]\n",
      "[ 2  7 12 13 18 20 22 24 27 29 34 38 40 44 47 50 52 54 56 58 60 62 64 68\n",
      " 71 72 74]\n",
      "La fréquence est de  0.03 %.\n",
      "La fréquence est de  2.22 %.\n",
      "La fréquence est de  0.09 %.\n",
      "La fréquence est de  2.44 %.\n",
      "La fréquence est de  0.13 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"Nous avons extrait les motifs suivants:\")\n",
    "for dsF in dsFrequence1:\n",
    "    print(dsF)\n",
    "for f in freq1:\n",
    "    print(\"La fréquence est de \", round(f*100,2), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaC_1QKKBlPb"
   },
   "source": [
    "Nous constatons que nous avons une bonne variété des motifs. Les échantillons tirés sont également différents les uns des autres, nous n'avons pas de redondance. \n",
    "Le bémol que nous pouvons soulevé, c'est qu'il semblerait que la majorité des lignes commencent par un 1, hors dans notre échantillon, il n'y en a qu'une sur les cinq. La proportion du nombre de ligne terminant par 74 semblent respectées. \n",
    "\n",
    "Nous avons une fréquence de nos motifs qui oscille entre 0,03% et 2,44% ce qui donne une fréquence moyenne de 0,98%. \n",
    "\n",
    "##### Algorithme de l'aire\n",
    "\n",
    "Dans un second temps, nous allons analyser l'algorithme de l'aire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgqpJxg8BkwH",
    "outputId": "311b25fc-ebf6-4a2e-9fbe-da01820f5f88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons extrait les motifs suivants:\n",
      "[ 3  5  9 11 13 15 19 23 27 31 34 48 52 56 70 72]\n",
      "[ 3 11 13 17 19 21 23 25 27 36 40 46 48 52 60 62 70 72]\n",
      "[ 1  3  5  7 11 15 21 27 34 36 38 40 44 46 54 60 64 70 72 74]\n",
      "[ 1  5 19 27 29 31 34 36 42 46 50 58 72]\n",
      "[ 3  7  9 13 21 23 25 29 31 34 38 42 44 52 58 62 66 74]\n",
      "\n",
      "L'aire totale du dataset est de : 118252 \n",
      "\n",
      "L'aire des motifs précédants est de: 1600  soit  1.35 % du dataset.\n",
      "L'aire des motifs précédants est de: 756  soit  0.64 % du dataset.\n",
      "L'aire des motifs précédants est de: 180  soit  0.15 % du dataset.\n",
      "L'aire des motifs précédants est de: 3354  soit  2.84 % du dataset.\n",
      "L'aire des motifs précédants est de: 2052  soit  1.74 % du dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"Nous avons extrait les motifs suivants:\")\n",
    "for dsA in dsArea1:\n",
    "    print(dsA)\n",
    "surface = dataset_1.shape\n",
    "s = surface[0]*surface[1]\n",
    "print(\"\\nL'aire totale du dataset est de :\", s, \"\\n\")\n",
    "for ar in area1: \n",
    "    print(\"L'aire des motifs précédants est de:\", ar, \" soit \", round((ar/s)*100, 2), \"% du dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons ici que l'aire des motifs varient énormément. Entre l'aire du motif le plus petit et l'aire du motif le plus grand il y a un rapport supérieur à 8. A nouveau, la méthode d'échantillonnage nous a permit d'obtenir une bonne diversité de motifs tirés. Une fois de plus, il semblerait que la part de ligne commençant par un 1 devrait être plus importante.\n",
    "\n",
    "Il est important de préciser, et cette précision sera valable pour l'ensemble des analyses de l'aire, que l'aire du dataset est calculée en fonction de la ligne la plus grande. C'est une aire théorique et dans le cas d'un dataset de 10 lignes si une ligne à 10 valeurs et les autres une seule, le dataset aura une aire estimé de 10x10 = 100 et non de 9x1+10x1 = 19. \n",
    "Cette pour cela que nos valeurs en pourcentage du dataset sont extrêmement faibles, nous sommes trop sensible à la présence d'une ligne beaucoup plus grande que les autres.\n",
    "Nous avons calculé l'aire ainsi afin de gagner du temps de calculs sur nos machines personnelles. \n",
    "\n",
    "#### Dataset n°2\n",
    "\n",
    "##### Algorithme de fréquence \n",
    "\n",
    "Comme pour le dataset précédant, nous allons dans un premier temps analyser l'algorithme de fréquence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccyKbbVRAwl6",
    "outputId": "765b523f-2e46-40e5-889f-80765e659127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons extrait les motifs suivants:\n",
      "['1' '-1' '1' '1' '-1' '-1' '-1' '1' '-1' '1' '-1' '-1' '1' '-1' '-1' '-1'\n",
      " '-1' '1' '-1' '1' '-1' '1' '1' '1' '-1' '-1' '1' '-1' '-1' '-1' '1' '1'\n",
      " '-1' '-1' '1' '-1' '1' '1' '-1' '1' '1' '-1' '-1' '1' '-1' '-1' '1' '-1'\n",
      " '1' '-1' '2372' '-1' '-1' '-1' '1' '2375' '54' '2376' '17' '-1']\n",
      "['1' '-1' '-1' '1' '-1' '-1' '1' '-1' '-1' '-1' '-1' '1' '-1' '1' '-1' '1'\n",
      " '1' '-1' '549' '-1' '1' '1' '-1' '1' '1' '-1' '1' '1' '-1' '-1' '1' '1'\n",
      " '1' '1' '1' '-1' '1' '363' '550' '1' '-1' '-1' '-1' '468' '-1' '555' '-1'\n",
      " '-1' '147' '-1' '-1' '500' '40' '29' '212' '559' '-2']\n",
      "['1' '-1' '-1' '-1' '1' '-1' '-1' '-1' '1' '-1' '-1' '-1' '-1' '1' '-1'\n",
      " '1' '1' '1' '-1' '1' '-1' '-1' '1' '1' '5772' '-1' '-1' '1' '1' '-1' '-1'\n",
      " '1' '-1' '1' '1' '1' '-1' '-1' '1' '1' '1' '-1' '-1' '-1' '-1' '1' '-1'\n",
      " '-1' '-1' '-1' '-1' '2873' '3991' '1' '1' '-1' '961' '-1' '175' '8' '-1'\n",
      " '29' '-1' '-1' '124' '632' '-1' '-1' '124' '-1' '130' '-1' '26']\n",
      "['1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1'\n",
      " '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1'\n",
      " '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1'\n",
      " '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '365' '-1' '2369'\n",
      " '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1'\n",
      " '-1' '1' '-1' '1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '363' '-1' '360'\n",
      " '-1' '2370' '-1' '1921' '-1' '1922' '-1' '2371' '-1' '1' '-1' '1' '-1'\n",
      " '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1'\n",
      " '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1'\n",
      " '-1' '1' '-1' '1' '-1' '1' '-1' '1' '-1' '1644' '-1' '2372' '-1' '2373'\n",
      " '-1' '2374' '-1' '1' '-1' '1' '-1' '1' '-1' '2375' '-1' '942' '-1' '21'\n",
      " '-1' '54' '-1' '989' '-1' '18' '-1' '2376' '-1' '17' '-1' '554' '-1' '29'\n",
      " '-1' '17' '-1']\n",
      "['-1' '-1' '-1' '1' '1' '-1' '1' '-1' '1' '-1' '1' '1' '-1' '-1' '1' '-1'\n",
      " '-1' '1' '1' '-1' '1' '1' '1' '1' '-1' '-1' '-1' '1' '365' '-1' '2369'\n",
      " '-1' '1' '1' '-1' '1' '1' '-1' '-1' '1' '-1' '1' '-1' '-1' '1' '1' '-1'\n",
      " '-1' '2370' '-1' '1922' '-1' '-1' '-1' '1' '-1' '1' '1' '-1' '1' '-1' '1'\n",
      " '-1' '-1' '1' '1' '-1' '-1' '-1' '1' '-1' '-1' '2372' '-1' '-1' '2374'\n",
      " '-1' '1' '-1' '-1' '-1' '-1' '18' '-1' '2376' '-1' '17' '554' '-1' '29'\n",
      " '-1' '17' '-1']\n",
      "La fréquence est de  0.0171 %.\n",
      "La fréquence est de  0.0171 %.\n",
      "La fréquence est de  0.0171 %.\n",
      "La fréquence est de  0.0171 %.\n",
      "La fréquence est de  0.0171 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"Nous avons extrait les motifs suivants:\")\n",
    "for dsF in dsFrequence2:\n",
    "    print(dsF)\n",
    "for f in freq2:\n",
    "    print(\"La fréquence est de \", round(f*100,4), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que la fréquence soit faible, nous constatons ici qu'elle est identique pour tout les échantillons obtenus. \n",
    "Après une analyse visuelle du fichier brut, la part de \"-1\" semble supérieur sur nos échantillons que dans le fichier brut. \n",
    "\n",
    "Nous pouvons également noter que la présence de nombres négatifs n'influe pas sur le déroulement de notre algorithme. \n",
    "\n",
    "##### Algorithme de l'aire\n",
    "\n",
    "Dans un second temps, nous allons analyser l'algorithme de l'aire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons extrait les motifs suivants:\n",
      "['781' '-1' '-1' '381' '-1' '1244' '-1' '8' '3224' '-1' '17' '-1' '52'\n",
      " '-1' '18' '-1' '8' '493' '103' '-1' '-1' '608' '-1' '14' '-1' '8' '-1'\n",
      " '-1' '-1' '-1' '97' '-1' '211' '-1' '8' '-1' '-2']\n",
      "['36' '-1' '21' '-1' '-1' '5824' '265' '-1' '-1' '71' '307' '8376' '779'\n",
      " '-1' '-1' '-1' '-1' '-1' '21' '-1' '4105' '-1' '8' '-1' '3711' '-1' '381'\n",
      " '351' '-1' '1356']\n",
      "['1' '-1' '-1' '-1' '1111' '-1' '103' '-1' '8' '-1' '1783' '-1' '-1' '122'\n",
      " '-1' '-1' '75' '-1' '-1' '2992' '-1' '29' '-1' '52' '-1' '-1' '1045' '-2']\n",
      "['1' '-1' '1' '-1' '-1' '18' '-1' '-1' '3256' '-1' '71' '-1' '312' '20'\n",
      " '-1' '1338' '318' '-1' '104' '-1' '-1' '-1' '18' '209' '-1' '206' '-1'\n",
      " '51' '-1' '-1' '1979' '-1' '8' '-1' '3065' '-1' '-2']\n",
      "['-1' '162' '-1' '7025' '54' '-1' '8' '2686' '-1' '-1' '6887' '-1' '2687'\n",
      " '-1' '21' '-1' '-1' '7026' '-1' '-1' '-1' '2138' '-1' '3' '-1' '-1' '177'\n",
      " '-1' '568' '5061']\n",
      "\n",
      "L'aire totale du dataset est de : 1085124 \n",
      "\n",
      "L'aire des motifs précédants est de: 37  soit  0.0034 % du dataset.\n",
      "L'aire des motifs précédants est de: 30  soit  0.0028 % du dataset.\n",
      "L'aire des motifs précédants est de: 28  soit  0.0026 % du dataset.\n",
      "L'aire des motifs précédants est de: 37  soit  0.0034 % du dataset.\n",
      "L'aire des motifs précédants est de: 30  soit  0.0028 % du dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"Nous avons extrait les motifs suivants:\")\n",
    "for dsA in dsArea2:\n",
    "    print(dsA)\n",
    "surface = dataset_2.shape\n",
    "s = surface[0]*surface[1]\n",
    "print(\"\\nL'aire totale du dataset est de :\", s, \"\\n\")\n",
    "for ar in area2: \n",
    "    print(\"L'aire des motifs précédants est de:\", ar, \" soit \", round((ar/s)*100, 4), \"% du dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois les valeurs présentes ici sont proches les une des autres. En revanche, pour ce dataset contrairement à l'algorithme de fréquence, nous avons une meilleure diversité des motifs tirés. \n",
    "\n",
    "On constate à nouveau que la présence de nombres négatifs n'a pas posé de problème.\n",
    "\n",
    "#### Dataset n°3\n",
    "\n",
    "##### Algorithme de fréquence \n",
    "\n",
    "Comme pour les datasets précédants, nous allons dans un premier temps analyser l'algorithme de fréquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccyKbbVRAwl6",
    "outputId": "765b523f-2e46-40e5-889f-80765e659127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons extrait les motifs suivants:\n",
      "['17' '-1' '-1' '17' '-1' '17' '-1' '-1' '17' '17' '-1' '17' '17' '-1'\n",
      " '17' '-1' '-1' '17' '-1' '17' '17' '-1' '-1' '-1' '17' '-1' '17' '-1'\n",
      " '-1' '17' '-1' '17' '-1' '-1' '17' '-1' '17' '-1' '17' '-1' '17' '-1'\n",
      " '17' '-1' '17' '-1' '17' '17' '17' '-1' '-1' '-1' '-1' '17' '-1' '17'\n",
      " '-1' '17' '17' '-1' '-1' '17' '17' '-1' '-1' '17' '17' '-1' '-1' '17'\n",
      " '-1' '17' '-1' '17' '-1' '-1' '-1' '17' '-1' '17' '17' '-1' '17' '17'\n",
      " '-1' '17' '-1' '17' '17' '-1' '17' '17' '-1' '17' '-1' '17' '-1' '17'\n",
      " '-1' '17' '-1' '17' '17' '-1' '17' '-1' '-1' '17' '-1' '-1' '-1' '17']\n",
      "['17' '-1' '48' '-1' '33' '-1' '-1' '47' '-1' '45' '15' '-1' '32' '-1'\n",
      " '-1' '135' '147' '-1' '131' '-1' '-1' '13' '-1' '90' '8' '18' '30' '31'\n",
      " '-1' '67' '-1' '70' '68' '-1' '96' '-1' '50' '-1' '44' '-1' '-1' '14'\n",
      " '-1' '10' '-1' '21' '-1' '24' '-1' '59' '-1' '-1' '37' '36' '-1' '118'\n",
      " '-1' '97' '-1' '98' '-1' '756' '-1' '-1' '163' '-1' '25' '173' '-1' '304'\n",
      " '-1' '11' '-1' '55' '40' '-1' '128' '54' '-1' '94' '-1' '95' '-1' '142'\n",
      " '-1' '202' '-1' '-1' '295' '-1' '137' '-1' '264' '-1' '328' '-1' '-1'\n",
      " '-1' '236' '-1' '296' '-1' '376' '-1' '292' '-1' '756' '77' '-1' '25'\n",
      " '625' '163' '-1' '-1' '30' '-1' '-1' '31' '-1' '17' '-1' '46' '-1' '33'\n",
      " '-1' '-1' '47' '-1' '-1']\n",
      "['-1' '37' '-1' '-1' '49' '-1' '1' '-1' '46' '-1' '48' '-1' '45' '-1' '18'\n",
      " '-1' '32' '-1' '47' '-1' '44' '-1' '57' '-1' '10' '-1' '2' '-1' '135'\n",
      " '-1' '50' '-1' '147' '-1' '155' '-1' '68' '-1' '30' '-1' '131' '-1' '90'\n",
      " '-1' '13' '-1' '67' '-1' '21' '-1' '98' '36' '-1' '82' '-1' '14' '-1'\n",
      " '24' '-1' '59' '31' '-1' '30' '-1' '117' '-1' '96' '-1' '-1' '181' '-1'\n",
      " '118' '-1' '70' '-1' '17' '-1' '1' '-1' '46' '-1' '45' '-1' '15' '-1'\n",
      " '47' '-1' '49' '-1' '48' '-1' '33' '-1' '32' '-1' '30' '-1' '67' '-1'\n",
      " '155' '-1' '131' '-1' '18' '-1' '97' '-1' '31' '-1' '2' '-1' '135' '-1'\n",
      " '50' '-1' '147' '-1' '90' '-1' '13' '82' '-1' '96' '-1' '44' '-1' '8'\n",
      " '-1' '68' '-1' '10' '-1' '59' '-1' '-1' '37' '-1' '70' '-1' '36' '-1'\n",
      " '21' '-1' '57' '-1' '14' '-1' '-1' '117' '-1' '-1' '98' '-1' '118' '-1'\n",
      " '297' '-1' '86' '100' '-1' '104' '-1' '197']\n",
      "['17' '-1' '45' '-1' '48' '32' '-1' '15' '-1' '-1' '47' '-1' '155' '8'\n",
      " '-1' '-1' '-1' '-1' '31' '-1' '82' '-1' '21' '57' '26' '26' '26' '59'\n",
      " '-1' '24' '36' '510' '306' '-1' '81' '306' '243' '-1' '18' '-1' '-1'\n",
      " '490' '-1' '-1' '81' '171' '-1' '211' '-1' '51' '-1' '214' '72' '-1' '28'\n",
      " '-1']\n",
      "['17' '46' '-1' '1' '-1' '15' '47' '-1' '155' '-1' '131' '-1' '-1' '50'\n",
      " '-1' '10' '59' '-1' '30' '-1' '37' '-1' '31' '-1' '33' '-1' '67' '-1'\n",
      " '48' '-1' '13' '-1' '44' '-1' '57' '-1' '-1' '-1' '2' '-1' '90' '-1' '96'\n",
      " '-1' '-1' '18' '29' '-1' '46' '-1' '72' '-1' '119' '121' '-1' '-1' '68'\n",
      " '-1' '-1' '51' '-1' '120' '-1' '27' '-1' '73' '-1' '166' '-1' '140' '-1'\n",
      " '57' '222' '-1' '14' '-1' '59' '48' '-1' '-1' '17' '50' '-1' '1' '-1'\n",
      " '-1' '-1' '2' '131' '-1' '21' '-1' '-1' '-1' '135' '-1' '30' '-1' '31'\n",
      " '-1' '8' '-1' '67' '-1' '117' '-1' '-1' '44' '-1' '-1' '-1' '24' '-1'\n",
      " '82' '-1' '1']\n",
      "La fréquence est de  0.0049 %.\n",
      "La fréquence est de  0.0049 %.\n",
      "La fréquence est de  0.0049 %.\n",
      "La fréquence est de  0.0049 %.\n",
      "La fréquence est de  0.0049 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"Nous avons extrait les motifs suivants:\")\n",
    "for dsF in dsFrequence3:\n",
    "    print(dsF)\n",
    "for f in freq3:\n",
    "    print(\"La fréquence est de \", round(f*100,4), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour le dataset n°2, nous obtenons une valeur pour la fréquence identique à tout les échantillons obtenus. Cela montre la régularité de l'algorithme de fréquence. \n",
    "La diversification des motifs semblent être plus importante qu'avec le dataset précédant.\n",
    "\n",
    "##### Algorithme de l'aire\n",
    "Dans un second temps, nous allons analyser l'algorithme de l'aire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons extrait les motifs suivants:\n",
      "['369' '2630' '-1' '2631' '80' '-1' '-1' '2547' '-1' '-1' '-1' '2634' '-1'\n",
      " '-1' '-1' '1005' '966' '-1' '-1' '-1' '-1' '939' '1129' '1020' '-1' '-1'\n",
      " '1180' '1150' '-1' '-1' '-2']\n",
      "['222' '-1' '-1' '-1' '-1' '-1' '185' '229' '-1' '-1' '27' '-1' '-1' '51'\n",
      " '72' '121' '-1' '-1' '166' '253' '99' '-1' '193' '-1' '-1' '225' '-1'\n",
      " '-2']\n",
      "['-1' '-1' '-1' '30' '-1' '97' '70' '-1' '147' '-1' '-1' '-1' '59' '181'\n",
      " '135' '90' '-1' '67' '-1' '117' '-1' '118' '-1' '13' '44' '82' '2' '-1'\n",
      " '98' '-1']\n",
      "['142' '-1' '328' '-1' '264' '-1' '279' '-1' '43' '-1' '-1' '236' '165'\n",
      " '43' '202' '-1' '142' '236' '-1' '279' '-1' '-1' '264' '-1' '-1' '116'\n",
      " '-1' '277' '292' '376' '-1' '322' '749' '-1']\n",
      "['15' '-1' '315' '-1' '33' '-1' '49' '-1' '30' '155' '70' '-1' '-1' '-1'\n",
      " '324' '98' '-1' '-1' '1' '-1' '-1' '21' '-1' '-1' '412' '-1' '57' '2'\n",
      " '-1' '37']\n",
      "\n",
      "L'aire totale du dataset est de : 3578750 \n",
      "\n",
      "L'aire des motifs précédants est de: 31  soit  0.0009 % du dataset.\n",
      "L'aire des motifs précédants est de: 28  soit  0.0008 % du dataset.\n",
      "L'aire des motifs précédants est de: 30  soit  0.0008 % du dataset.\n",
      "L'aire des motifs précédants est de: 34  soit  0.001 % du dataset.\n",
      "L'aire des motifs précédants est de: 30  soit  0.0008 % du dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"Nous avons extrait les motifs suivants:\")\n",
    "for dsA in dsArea3:\n",
    "    print(dsA)\n",
    "surface = dataset_3.shape\n",
    "s = surface[0]*surface[1]\n",
    "print(\"\\nL'aire totale du dataset est de :\", s, \"\\n\")\n",
    "for ar in area3: \n",
    "    print(\"L'aire des motifs précédants est de:\", ar, \" soit \", round((ar/s)*100, 4), \"% du dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater à nouveau que les valeurs sont très proches les une des autres. Les échantillons ont toujours des motifs diversifiés. Les motifs sont également tirés proportionnellement. \n",
    "\n",
    "#### Dataset n°4\n",
    "\n",
    "##### Algorithme de fréquence \n",
    "\n",
    "Comme pour les datasets précédants, nous allons dans un premier temps analyser l'algorithme de fréquence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgqpJxg8BkwH",
    "outputId": "311b25fc-ebf6-4a2e-9fbe-da01820f5f88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons extrait les motifs suivants:\n",
      "['-1' '77' '-1' '38' '-1' '-1' '5579' '-1' '31' '-1' '38' '-1' '10' '-1'\n",
      " '-1' '46' '-1' '-1' '3997' '-1' '4' '-1' '669' '-1' '544' '-1' '2017'\n",
      " '-1' '38' '-1' '22' '661' '-1' '51' '456' '-1' '15' '-1' '61' '-1' '269'\n",
      " '-1' '10352' '-1' '38' '-1' '10' '-1' '46' '-1' '374' '356' '-1' '-1'\n",
      " '22' '-1' '-1' '-1' '46' '10' '-1' '1595' '-1' '31' '-1' '10' '-1' '2742'\n",
      " '-1' '46' '-1' '10' '-1' '318' '31' '-1' '10' '-1' '131' '-1' '-1' '10'\n",
      " '-1' '2531' '-1' '31' '-1' '218' '2513' '-1' '3' '-1' '-1' '188' '-1'\n",
      " '10' '-1' '926' '-1' '31' '-1' '218' '-1' '10' '-1' '222' '-1' '-1' '127'\n",
      " '-1' '-1' '10' '-1' '157' '10' '-1' '926' '-1' '456' '7165' '-1' '-1'\n",
      " '1585' '-1' '31' '-1' '-1' '2784' '-1' '456' '-1' '-1' '4618' '-1' '-1'\n",
      " '31' '-1']\n",
      "['356' '-1' '-1' '14' '41' '46' '-1' '-1' '-1' '14' '-1' '15' '-1' '16'\n",
      " '1209' '-1' '8' '-1' '10' '-1' '955' '10' '5714' '-1' '1283' '-1' '15'\n",
      " '-1' '65' '8' '-1' '218' '-1' '-1' '2494' '-1' '8' '-1' '22' '-1' '325'\n",
      " '-1' '46' '10' '-1' '33' '-1' '8' '-1' '328' '23' '41' '-1' '46' '-1'\n",
      " '10' '-1' '46' '-1' '3180' '-1' '10' '-1' '428' '46' '-1' '702' '-1'\n",
      " '218' '-1' '356' '-1' '351' '-1' '14' '-1' '41' '-1' '772' '669' '-1'\n",
      " '-1' '234' '-1' '748' '61' '-1' '428' '46' '73' '657' '-1' '384' '-1'\n",
      " '998' '-1' '267' '761' '-1' '392' '-1' '-1' '13221' '-1' '10' '-1' '951'\n",
      " '31' '-1' '906' '172' '3' '-1' '-1' '15' '-1' '-1' '72' '-1' '245' '113'\n",
      " '-1' '246']\n",
      "['-1' '41' '14' '15' '16' '1209' '-1' '-1' '-1' '15' '10' '-1' '8' '41'\n",
      " '46' '33' '22' '46' '-1' '485' '-1' '-1' '186' '-1' '46' '-1' '-1' '41'\n",
      " '772' '-1' '4' '428' '-1' '267' '-1' '-1' '15' '-1' '59' '-1' '245' '-1'\n",
      " '-2']\n",
      "['356' '-1' '-1' '-1' '-1' '485' '-1' '22' '-1' '1283' '-1' '15' '-1' '-1'\n",
      " '1209' '-1' '8' '-1' '10' '-1' '955' '-1' '10' '-1' '-1' '1283' '-1' '-1'\n",
      " '-1' '8' '-1' '218' '-1' '10' '-1' '2494' '-1' '8' '22' '325' '-1' '41'\n",
      " '-1' '46' '-1' '10' '241' '-1' '-1' '-1' '22' '-1' '328' '-1' '23' '-1'\n",
      " '-1' '46' '-1' '-1' '-1' '-1' '186' '-1' '41' '-1' '-1' '46' '-1' '702'\n",
      " '218' '-1' '14' '-1' '-1' '669' '-1' '234' '-1' '748' '61' '428' '-1'\n",
      " '-1' '656' '-1' '384' '-1' '267' '-1' '-1' '388' '-1' '392' '-1' '186'\n",
      " '-1' '13221' '-1' '10' '-1' '951' '-1' '-1' '906' '-1' '172' '-1' '-1'\n",
      " '15' '59' '72' '245' '113' '-1' '246' '-1']\n",
      "['356' '-1' '14' '41' '485' '-1' '14' '15' '-1' '-1' '8' '-1' '10' '-1'\n",
      " '-1' '5714' '1283' '15' '-1' '65' '-1' '10' '2494' '325' '-1' '41' '10'\n",
      " '-1' '241' '33' '8' '-1' '-1' '328' '23' '41' '46' '10' '-1' '46' '-1'\n",
      " '3180' '-1' '186' '10' '-1' '46' '218' '-1' '-1' '351' '-1' '14' '41'\n",
      " '669' '-1' '-1' '-1' '-1' '-1' '46' '-1' '73' '-1' '657' '656' '-1' '-1'\n",
      " '267' '761' '-1' '388' '-1' '-1' '13221' '10' '951' '-1' '-1' '-1' '3'\n",
      " '-1' '-1' '-1' '113' '-2']\n",
      "La fréquence est de  0.0027 %.\n",
      "La fréquence est de  0.0027 %.\n",
      "La fréquence est de  0.0027 %.\n",
      "La fréquence est de  0.0027 %.\n",
      "La fréquence est de  0.0027 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"Nous avons extrait les motifs suivants:\")\n",
    "for dsF in dsFrequence4:\n",
    "    print(dsF)\n",
    "for f in freq4:\n",
    "    print(\"La fréquence est de \", round(f*100,4), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois de plus nous constatons que l'algorithme de fréquence ressort des valeurs identiques. Les motifs sont diversifiés. \n",
    "\n",
    "##### Algorithme de l'aire\n",
    "Dans un second temps, nous allons analyser l'algorithme de l'aire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous avons extrait les motifs suivants:\n",
      "['-1' '-1' '14' '2123' '-1' '663' '-1' '305' '-1' '881' '-1' '38' '1134'\n",
      " '-1' '73' '-1' '12644' '3038' '-1' '2123' '31' '-1' '-1' '-1' '43' '384'\n",
      " '-1' '31' '-1' '121' '11354' '-2']\n",
      "['-1' '-1' '-1' '2836' '-1' '-1' '560' '59' '12' '-1' '31' '456' '-1'\n",
      " '396' '-1' '2546' '55' '560' '-1' '5333' '-1' '-1' '55' '-1' '560' '5352']\n",
      "['5736' '61' '-1' '8' '-1' '-1' '116' '-1' '12' '4228' '-1' '-1' '794'\n",
      " '-1' '2430' '-1' '560' '10' '-1' '4530' '-1' '46' '-1' '560' '-1' '8036'\n",
      " '-1' '-2']\n",
      "['-1' '10' '-1' '-1' '-1' '-1' '535' '22' '11330' '583' '-1' '1141' '-1'\n",
      " '10' '2794' '-1' '46' '-1' '243' '-1' '-1' '10' '-1' '363' '-1' '46' '-1']\n",
      "['356' '-1' '129' '-1' '10' '-1' '3736' '-1' '456' '15' '31' '-1' '10'\n",
      " '-1' '4139' '22' '-1' '4238' '116' '-1' '51' '-1' '61' '-1' '3318' '890'\n",
      " '-1' '1232' '31' '-1' '-2']\n",
      "\n",
      "L'aire totale du dataset est de : 6364575 \n",
      "\n",
      "L'aire des motifs précédants est de: 32  soit  0.0005 % du dataset.\n",
      "L'aire des motifs précédants est de: 26  soit  0.0004 % du dataset.\n",
      "L'aire des motifs précédants est de: 28  soit  0.0004 % du dataset.\n",
      "L'aire des motifs précédants est de: 27  soit  0.0004 % du dataset.\n",
      "L'aire des motifs précédants est de: 31  soit  0.0005 % du dataset.\n"
     ]
    }
   ],
   "source": [
    "print(\"Nous avons extrait les motifs suivants:\")\n",
    "for dsA in dsArea4:\n",
    "    print(dsA)\n",
    "surface = dataset_4.shape\n",
    "s = surface[0]*surface[1]\n",
    "print(\"\\nL'aire totale du dataset est de :\", s, \"\\n\")\n",
    "for ar in area4: \n",
    "    print(\"L'aire des motifs précédants est de:\", ar, \" soit \", round((ar/s)*100, 4), \"% du dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb1rrE2JpwWi"
   },
   "source": [
    "Nous constatons à nouveau pour ce dernier dataset que les valeurs retournées sont très proches les unes des autres. Les motifs sont tirés de manière diversifiée dans le dataset.\n",
    "\n",
    "## Question 6\n",
    "\n",
    "On a constaté que lorsque l'on avait une ligne beaucoup plus grande que les autres, les algorithmes de fréquence et d'aire favorisent la ligne la plus grande pour créer des motifs. Ce comportement est lié au poids attribué à la ligne la plus grande. Nous souhaitons trouver des motifs fréquents, donc nous souhaitons éviter des motifs qui s'appliquent seulement dans des grandes lignes. Nous avons trouver trois solutions:\n",
    "\n",
    "*   Supprimer les grandes lignes du dataset\n",
    "*   Réduire la taille des grandes lignes\n",
    "*   Modifier le poids accorder à la ligne la plus grande, cette option n'implique pas de perte de données dans le dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "gnCJcK6EpzfI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>28</td>\n",
       "      <td>-1</td>\n",
       "      <td>58</td>\n",
       "      <td>-1</td>\n",
       "      <td>61</td>\n",
       "      <td>-1</td>\n",
       "      <td>64</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>-1</td>\n",
       "      <td>255</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>54</td>\n",
       "      <td>-1</td>\n",
       "      <td>55</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-1</td>\n",
       "      <td>72</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0   1   2   3   4   5    6   7   8   9    ...   165   166   167   168   169  \\\n",
       "0   3  -1  28  -1  58  -1   61  -1  64  -1  ...  None  None  None  None  None   \n",
       "1   4  -1   7  -1  23  -1  255  -1   3  -1  ...  None  None  None  None  None   \n",
       "2   8  -1  10  -1  13  -1   14  -1  21  -1  ...  None  None  None  None  None   \n",
       "3  11  -1  25  -1  40  -1   54  -1  55  -1  ...  None  None  None  None  None   \n",
       "4  12  -1  39  -1  63  -1   72  -1   3  -1  ...  None  None  None  None  None   \n",
       "\n",
       "    170   171   172   173   174  \n",
       "0  None  None  None  None  None  \n",
       "1  None  None  None  None  None  \n",
       "2  None  None  None  None  None  \n",
       "3  None  None  None  None  None  \n",
       "4  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsetGL = pd.read_fwf(\"https://www.philippe-fournier-viger.com/spmf/datasets/LEVIATHAN.txt\", sep=\" \",header=None,)\n",
    "df_gl= dsetGL[0].str.split(' ', expand=True)\n",
    "ds_gl = DataSet(df_gl)\n",
    "ds_gl.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUPGML_e0P3n"
   },
   "source": [
    "## Cas où le dataset est chargé dans un df\n",
    "Dans cette option, nous allons calculer la moyenne du nombre d'items par ligne et en fonction de cela, nous supprimerons les colonnes avec une taille supérieure à la taille moyenne du nombre d'items par ligne. \n",
    "Nous nous concentrons sur une partie du dataset, dans l'exemple 40%, afin de gagner du temps lors de l'exécution. Ce seuil est paramétrable dans l'appel à la fonction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTHpqbKq3eBP",
    "outputId": "5f49c271-5cf3-48ad-cb7a-c3b7ca059980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20450, 175)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_gl.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "x68bs1ADzJG9"
   },
   "outputs": [],
   "source": [
    "def resizeDataSet(ds,percentage):\n",
    "  df = ds.df\n",
    "  shape = ds.df.shape\n",
    "  sum = 0\n",
    "  #for index, row in df.iterrows():\n",
    "  for _ in range(int(shape[0]*percentage)):\n",
    "    #if random.uniform(0.,100.) < 5.:\n",
    "    sum += shape[1] - ds.sizes[random.randint(0,shape[0]-1)]\n",
    "  mean = sum/(shape[0]*percentage)\n",
    "  for i in range(shape[1]-1,int(mean),-1):\n",
    "    del df[i]\n",
    "  for i in range(shape[0]):\n",
    "    if ds.sizes[i] > mean:\n",
    "        ds.sizes[i] = math.ceil(mean)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "zz-j87LP5sVr",
    "outputId": "5b060021-bcb9-43c0-80c0-659f1befeabc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20450, 103)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resizeDataSet(ds_gl,0.4)\n",
    "ds_gl.df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykMFpM-61PFD"
   },
   "source": [
    "Comme vous pouvez le constater, nous avons réduit le nombre de colones du dataset afin de gagner du temps lors de l'exécution des algorithmes. \n",
    "Cette solution pose un problème dans le cas ou les datarecords sont ordonnées. En supprimant les colonnes supérieurs à la taille moyenne, nous pouvons perdre, par exemple, les valeurs les plus grandes dans le cadre d'un classement par ordre croissant.\n",
    "\n",
    "## Troisième solution\n",
    "\n",
    "Dans cette approche, nous réalisons une moyenne mobile pour l'attribution du poids. De cette manière, nous ne supprimons pas de valeurs dans le dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "D24SfrAUYUj7"
   },
   "outputs": [],
   "source": [
    "def algoFrequencesSolutionA(ds,nb_pattern)-> tuple:\n",
    "  df = ds.df\n",
    "  sizes = ds.sizes\n",
    "  R = []\n",
    "  IsInR = set()\n",
    "  w = np.zeros(df.shape[0])\n",
    "  totalW = 0\n",
    "    \n",
    "  # set les probas\n",
    "  for i in range(len(w)):\n",
    "    w[i] = math.pow(2,sizes[i])\n",
    "    if i >= 2:\n",
    "      w[i] = (w[i] + w[i-1] + w[i-2])/ 3\n",
    "    totalW += w[i]\n",
    "  # on selectionne \n",
    "  while len(R) < nb_pattern:\n",
    "    random_row = random.uniform(0,totalW)\n",
    "    # On cherche la ligne\n",
    "    row = 0\n",
    "    v = 0\n",
    "    for i in range(len(w)):\n",
    "      if  v > random_row:\n",
    "        row = i - 1\n",
    "        break\n",
    "      v += w[i]\n",
    "    # On selectionne un motif \n",
    "    pattern = np.array(df.iloc[row][:sizes[row]])\n",
    "    random_v = random.randint(1, len(pattern) - 1 )\n",
    "    for i in range(len(pattern)- random_v):\n",
    "      pattern = np.delete(pattern, random.randint(0, len(pattern) - 1 ))\n",
    "    # On ajoute seulement les motifs non présents dans l'ensemble R\n",
    "    IsInR.add(np.array2string(pattern))\n",
    "    if len(IsInR) != len(R):\n",
    "      R.append(pattern)\n",
    "  print(R)\n",
    "  return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>38</td>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>-1</td>\n",
       "      <td>64</td>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>65</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "      <td>-1</td>\n",
       "      <td>80</td>\n",
       "      <td>-1</td>\n",
       "      <td>81</td>\n",
       "      <td>-1</td>\n",
       "      <td>82</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>156</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>172</td>\n",
       "      <td>-1</td>\n",
       "      <td>173</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3    4   5    6   7    8   9    ...   176   177   178   179  \\\n",
       "0   36  -1  37  -1   38  -1   17  -1   39  -1  ...  None  None  None  None   \n",
       "1   36  -1  64  -1   17  -1    8  -1   65  -1  ...  None  None  None  None   \n",
       "2   78  -1  79  -1   80  -1   81  -1   82  -1  ...  None  None  None  None   \n",
       "3  155  -1   8  -1  156  -1   14  -1  157  -1  ...  None  None  None  None   \n",
       "4    1  -1   1  -1    1  -1  172  -1  173  -1  ...  None  None  None  None   \n",
       "\n",
       "    180   181   182   183   184   185  \n",
       "0  None  None  None  None  None  None  \n",
       "1  None  None  None  None  None  None  \n",
       "2  None  None  None  None  None  None  \n",
       "3  None  None  None  None  None  None  \n",
       "4  None  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsetGL = pd.read_fwf(\"https://www.philippe-fournier-viger.com/spmf/datasets/LEVIATHAN.txt\", sep=\" \",header=None,)\n",
    "df_gl= dsetGL[0].str.split(' ', expand=True)\n",
    "ds_gl = DataSet(df_gl)\n",
    "ds_gl.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "cpKfHwKxoIq8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['206', '-1', '54', '-1', '-1'], dtype=object), array(['310', '-1', '20', '-1', '-1', '-1', '731', '-1', '18', '-1', '96',\n",
      "       '-1', '4466', '5776', '-1', '8', '193', '-2'], dtype=object), array(['14', '-1', '436', '-1', '219', '-1', '355', '-1', '58', '567',\n",
      "       '-1', '568', '41', '-1', '71', '-1', '569', '-1', '14', '-1',\n",
      "       '570', '-1', '220', '-1', '571', '-1', '468', '-1', '572', '-1',\n",
      "       '573', '-1', '18', '-1', '41', '-1', '14', '-1', '574', '-1',\n",
      "       '575', '18', '-1', '-1', '319', '-1', '576', '-1', '577', '-1',\n",
      "       '578', '579', '-1', '30', '-1', '290', '-1', '52', '-1', '45',\n",
      "       '-1', '23', '-1', '41', '-1', '580', '-1', '29', '-1', '278', '18',\n",
      "       '-1', '398', '-1', '219', '355', '21', '-1', '58', '441', '-1',\n",
      "       '-2'], dtype=object), array(['-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '1', '-1', '-1', '1',\n",
      "       '-1', '1', '1', '2369', '-1', '-1', '-1', '-1', '-1', '1', '363',\n",
      "       '360', '1921', '-1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1',\n",
      "       '-1', '-1', '1', '-1', '1', '2374', '-1', '21', '54', '18', '-1',\n",
      "       '-1'], dtype=object), array(['-1', '-1', '-1', '58', '-1', '398'], dtype=object), array(['1', '1', '1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1',\n",
      "       '365', '-1', '2369', '-1', '1', '1', '1', '1', '-1', '1', '-1',\n",
      "       '-1', '-1', '54', '-1'], dtype=object), array(['1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1',\n",
      "       '1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '1', '-1', '1',\n",
      "       '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1',\n",
      "       '-1', '1', '-1', '1', '-1', '1', '-1', '1', '1', '-1', '1', '1',\n",
      "       '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '365',\n",
      "       '-1', '549', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1',\n",
      "       '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1',\n",
      "       '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1',\n",
      "       '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1',\n",
      "       '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1',\n",
      "       '363', '-1', '1', '-1', '1', '-1', '1', '-1', '551', '-1', '266',\n",
      "       '-1', '40', '493', '-1', '552', '-1', '500', '-1', '553', '-1',\n",
      "       '554', '-1', '468', '-1', '-1', '30', '-1', '30', '-1', '147',\n",
      "       '-1', '556', '-1', '500', '-1', '103', '-1', '557', '-1', '17',\n",
      "       '40', '-1', '558', '-1', '29', '-1', '212', '-1', '19', '-1',\n",
      "       '559', '-1', '18', '-1', '-2'], dtype=object), array(['294', '-1', '71', '-1', '29', '-1', '1641', '-1', '-1', '-1',\n",
      "       '-1', '227', '-1', '-1', '18', '152', '2672', '21', '71', '347',\n",
      "       '-1', '-1'], dtype=object), array(['36', '-1', '234', '-1', '-1', '24', '-1', '160', '-1', '2379',\n",
      "       '21', '-1', '54', '-1', '206', '-1', '235', '-1', '2380', '-1'],\n",
      "      dtype=object), array(['1', '1', '-1', '1', '1', '1', '1', '-1', '-1', '1', '-1', '1',\n",
      "       '-1', '1', '1', '-1', '-1', '1', '-1', '-1', '1', '1', '1', '-1',\n",
      "       '-1', '1', '-1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '1',\n",
      "       '-1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '-1', '1', '-1',\n",
      "       '1', '-1', '363', '2873', '3991', '-1', '1', '-1', '961', '152',\n",
      "       '-1', '175', '-1', '535', '-1', '8', '-1', '29', '124', '-1',\n",
      "       '3442', '-1', '436', '-1', '-1', '-1', '26', '-1', '29', '-1',\n",
      "       '193'], dtype=object)]\n",
      "frequence 1.5084%\n",
      "frequence 0.0171%\n",
      "frequence 0.0171%\n",
      "frequence 0.0171%\n",
      "frequence 0.0514%\n",
      "frequence 0.0171%\n",
      "frequence 0.0171%\n",
      "frequence 0.0171%\n",
      "frequence 0.0171%\n",
      "frequence 0.0171%\n"
     ]
    }
   ],
   "source": [
    "patterns = algoFrequencesSolutionA(ds_gl,10)\n",
    "fre = frequences(ds_gl,patterns)\n",
    "for f in fre:\n",
    "    print(f\"frequence {round(f*100.0,4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant cette méthode, nous obtenons une fréquence proche entre les diverses échantillons. La diversité est présente, mais il semblerait que cette solution ne soit pas aussi efficace qu'esperé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "TP_DataMining",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
